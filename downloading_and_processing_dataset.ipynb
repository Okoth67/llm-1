{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cff6badd-013a-4a84-b26f-37531d52067b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection\\SMSSpamCollection.tsv already exists, skipping download and unzipping.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import ssl\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f'{data_file_path} already exists, skipping download and unzipping.')\n",
    "        return\n",
    "\n",
    "    # Download the file WITHOUT custom SSL context\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, 'wb') as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzip the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Rename the file to have .tsv extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f'File downloaded and saved as {data_file_path}')\n",
    "\n",
    "\n",
    "# Run the function\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a1eac54-f822-4171-8d4c-61465cb81a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                            message\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Update the path if necessary\n",
    "data_file_path = \"sms_spam_collection/SMSSpamCollection.tsv\"\n",
    "\n",
    "# Load it into a DataFrame\n",
    "df = pd.read_csv(data_file_path, sep='\\t', header=None, names=[\"label\", \"message\"])\n",
    "\n",
    "# Show first 5 rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0b4d148-d2f2-4b8e-9d1b-9ff0f60af39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#creating a value counts to see the classifications\n",
    "print(df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5a6221f-6ebc-4d52-be2a-78cd270a795e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#we then proceed to make the dataset balance\n",
    "# Load the dataset (adjust the path if needed)\n",
    "\n",
    "data_file_path = \"sms_spam_collection/SMSSpamCollection.tsv\"\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep='\\t', header=None, names=[\"label\", \"message\"])\n",
    "\n",
    "def create_balanced_dataset(df):\n",
    "    # Count the number of spam messages\n",
    "    num_spam = df[df[\"label\"] == 'spam'].shape[0]\n",
    "\n",
    "    # Randomly sample ham messages to match the number of spam messages\n",
    "    ham_subset = df[df[\"label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "\n",
    "    # Combine the ham subset with all spam messages\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"label\"] == \"spam\"]])\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "# Now create the balanced dataset\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "\n",
    "# Check the class distribution\n",
    "print(balanced_df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18e25752-ba22-4d16-a2ac-bb4cf32ef0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we then convert the string class labels ie ham and spam into 1 and 0 respectively\n",
    "balanced_df['label'] = balanced_df['label'].map({'ham':0, 'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78df46e0-7690-4cd2-8bd1-081c759fd40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a random split function to split the dataset into 3\n",
    "#the 3 are training data, validation data and test data\n",
    "#the ratio is usually 7.1.2\n",
    "#or 70% to train, 10% to validate and 20% to test\n",
    "def random_split(df, train_frac, validation_frac):\n",
    "    #shuffle the entire dataset first\n",
    "    df = df.sample(frac = 1, random_state = 123).reset_index(drop = True)\n",
    "\n",
    "    #calc split indices\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    #split the dataframe\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end : validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8132ba94-c3be-4c95-986e-db84094950e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045\n",
      "149\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))\n",
    "print(len(validation_df))\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5209fb3-7aba-4c63-945c-8167ef0c0487",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the dataframes to csv file to reuse later\n",
    "train_df.to_csv('train.csv', index = None)\n",
    "validation_df.to_csv('validation.csv', index = None)\n",
    "test_df.to_csv('test.csv', index = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ce84eb-b156-4747-b9e9-a2258dd9587d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
